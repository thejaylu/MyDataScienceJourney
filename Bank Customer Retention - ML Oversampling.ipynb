{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "This bank's customers are leaving slowly, but surely. It's been identified that it is cheaper to maintain of existing customers than to attract new ones. The data provided are clientsâ€™ past behavior and termination of contracts with the bank. A model will be needed to predict if a customer is on the verge of leaving the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "df = pd.read_csv('Churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tenure']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsWithNaN = []\n",
    "for x in df.columns:\n",
    "    if df[df[x].isnull()].empty == False: \n",
    "            columnsWithNaN.append(x)\n",
    "columnsWithNaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Tenure column has Not A Number values that need to be fixed to continue to modeling. The median is very close to 0 so I believe filling in the null values to the median should be appropriate for the model to assess as an appropriate characteristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep: One-Hot Encoding and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: Geography, dtype: int64\n",
      "\n",
      "Male      5457\n",
      "Female    4543\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Geography'].value_counts()); print()\n",
    "print(df['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have identified the categorical features in this data set as Geography and Gender. These columns will need to be converted to dummy variables for the model to understand categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------- Minimum -----------\n",
      "\n",
      "CreditScore        350.00\n",
      "Age                 18.00\n",
      "Tenure               0.00\n",
      "Balance              0.00\n",
      "NumOfProducts        1.00\n",
      "EstimatedSalary     11.58\n",
      "dtype: float64\n",
      "\n",
      "----------- Maximum -----------\n",
      "\n",
      "CreditScore           850.00\n",
      "Age                    92.00\n",
      "Tenure                 10.00\n",
      "Balance            250898.09\n",
      "NumOfProducts           4.00\n",
      "EstimatedSalary    199992.48\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n----------- Minimum -----------\\n\")\n",
    "print(df[['CreditScore', 'Age', 'Tenure', 'Balance','NumOfProducts','EstimatedSalary']].min())\n",
    " \n",
    "print(\"\\n----------- Maximum -----------\\n\")\n",
    "print(df[['CreditScore', 'Age', 'Tenure', 'Balance','NumOfProducts','EstimatedSalary']].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of these features are fairly large. Feature scaling is required here otherwise the features that have lower numerical values will be heavily overshadowed by the larger features in terms of significance in the training model. This will be performed using the sklearn StandardScaler module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Define which columns should be encoded vs scaled\n",
    "columns_to_encode = ['Geography','Gender']\n",
    "columns_to_scale  = ['CreditScore','Age','Tenure', 'Balance','NumOfProducts','EstimatedSalary']\n",
    "\n",
    "# Instantiate encoder/scaler\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Scale and Encode Separate Columns\n",
    "scaled_columns  = scaler.fit_transform(df[columns_to_scale]) \n",
    "encoded_columns = ohe.fit_transform(df[columns_to_encode]) #purposefully left out Surname \n",
    "\n",
    "# Concatenate (Column-Bind) Processed Columns Back Together\n",
    "df2 = np.concatenate([scaled_columns, encoded_columns], axis=1)\n",
    "\n",
    "# https://stackoverflow.com/questions/43798377/one-hot-encode-categorical-variables-and-scale-continuous-ones-simultaneouely "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have modified categorial columns Geography and Gender into dummy variable columns. Scaled data can be found in continuous numerical columns CreditScore, Age, Tenure, Balance, Number of Products, and Estimated Salary so there is greater significance balance between them. A new dataframe called \"df2\" was created that concatenated these now encoded and scaled columns now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Male</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.087768</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age    Tenure   Balance  NumOfProducts  EstimatedSalary  \\\n",
       "0    -0.326221  0.293517 -1.086246 -1.225848      -0.911583         0.021886   \n",
       "1    -0.440036  0.198164 -1.448581  0.117350      -0.911583         0.216534   \n",
       "2    -1.536794  0.293517  1.087768  1.333053       2.527057         0.240687   \n",
       "3     0.501521  0.007457 -1.448581 -1.225848       0.807737        -0.108918   \n",
       "4     2.063884  0.388871 -1.086246  0.785728      -0.911583        -0.365276   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Male  HasCrCard  IsActiveMember  Exited  \n",
       "0                0.0              0.0   0.0          1               1       1  \n",
       "1                0.0              1.0   0.0          0               1       0  \n",
       "2                0.0              0.0   0.0          1               0       1  \n",
       "3                0.0              0.0   0.0          0               0       0  \n",
       "4                0.0              1.0   0.0          1               1       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(df2, columns=['CreditScore','Age','Tenure', 'Balance','NumOfProducts','EstimatedSalary',\n",
    "                                'Geography_France','Geography_Germany','Geography_Spain','Female','Male'])\n",
    "df2 = df2.drop(['Geography_France', 'Female'], axis=1) #To avoid dummy trap \n",
    "df2['HasCrCard'] = pd.Series(df['HasCrCard'])\n",
    "df2['IsActiveMember'] = pd.Series(df['IsActiveMember'])\n",
    "df2['Exited'] = pd.Series(df['Exited'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe df2 was modified to remove columns Geography_France and Female to prevent the dummy trap. Binary columns Has Credit Card, Is Active Member, and Exited were then added with no changes to them because it would be inaccurate to scale them. Columns that would act as noise to the model such as surname, rownumber, and customerid were removed from the dataframe to improve accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep: How is the balance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2037 / (2037 + 7963)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant class imbalance. The majority is the 0 classification for 'Exited' where the customer has not left; shown around 80% of the dataset. The minority is the 1 classification for 'Exited' where the customer has left; shown as 20% of the dataset. Training the data with a large amount of 0 classifications will cause the model to prefer predicting observations as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "target = df2['Exited']\n",
    "features = df2.drop('Exited', axis=1)\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, \n",
    "                                                                            test_size=0.2, random_state=12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, \n",
    "                                                                       test_size=0.25, random_state=12345) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:  10 , training accuracy: 0.9045 ,validation accuracy: 0.864\n",
      "f1: 0.548172757475083 auc: 0.696702849540389\n",
      "depth:  12 , training accuracy: 0.9336666666666666 ,validation accuracy: 0.8615\n",
      "f1: 0.5436573311367381 auc: 0.6951490894409484\n",
      "depth:  14 , training accuracy: 0.9706666666666667 ,validation accuracy: 0.863\n",
      "f1: 0.5537459283387622 auc: 0.7009214472937552\n",
      "depth:  16 , training accuracy: 0.9945 ,validation accuracy: 0.862\n",
      "f1: 0.551948051948052 auc: 0.7002999432539789\n",
      "depth:  18 , training accuracy: 0.9995 ,validation accuracy: 0.8605\n",
      "f1: 0.5521669341894061 auc: 0.7013037279115716\n",
      "depth:  20 , training accuracy: 1.0 ,validation accuracy: 0.861\n",
      "f1: 0.5544871794871795 auc: 0.7025825002900882\n"
     ]
    }
   ],
   "source": [
    "for d in range(10,21,2):\n",
    "    model = RandomForestClassifier(random_state=12345, max_depth = d, n_estimators = 1000)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    auc_roc = roc_auc_score(target_valid, model.predict(features_valid))\n",
    "\n",
    "    print('depth: ',d,', training accuracy:', model.score(features_train, target_train), \n",
    "          ',validation accuracy:', model.score(features_valid, target_valid))\n",
    "    print('f1:', f1_score(target_valid, predicted_valid), 'auc:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through hyperparameter looping, I did identify that max_depth = 18 and n_estimators = 1000 was the optimal configuration for the imbalanced random forest classifier model. These hyperparameters generated an output of f1 = 0.55 and auc_roc = 0.7013. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def balance_resample(features, target, direction, factor):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    if direction == 'up':\n",
    "        #this will upsample the count of ones\n",
    "        features_resample = pd.concat([features_zeros] + [features_ones] * factor)\n",
    "        target_resample = pd.concat([target_zeros] + [target_ones] * factor)\n",
    "        features_resample, target_resample = shuffle(features_resample, target_resample, random_state=12345)\n",
    "    elif direction == 'down': \n",
    "        #this will downsample the count of zeroes \n",
    "        features_resample = pd.concat([features_zeros.sample(frac=factor, random_state=12345)] + [features_ones])\n",
    "        target_resample = pd.concat([target_zeros.sample(frac=factor, random_state=12345)] + [target_ones])\n",
    "    else: \n",
    "        print('no direction')\n",
    "    return features_resample, target_resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function for both upsampling and downsampling. I am aware that is this is automatically assuming that classification 0 is the majority and classification 1 is the minority. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalance: Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       d: 8 -------------\n",
      "training accuracy: 0.8486072279175727 ,validation accuracy: 0.805\n",
      "f1: 0.5788336933045356 Area under curve score: 0.7597402081323248\n",
      "       d: 10 -------------\n",
      "training accuracy: 0.9046287666977322 ,validation accuracy: 0.824\n",
      "f1: 0.5999999999999999 Area under curve score: 0.7676767034535597\n",
      "       d: 12 -------------\n",
      "training accuracy: 0.9715232473853164 ,validation accuracy: 0.835\n",
      "f1: 0.5975609756097561 Area under curve score: 0.756120861077157\n",
      "       d: 14 -------------\n",
      "training accuracy: 0.9953401677539608 ,validation accuracy: 0.844\n",
      "f1: 0.5948051948051948 Area under curve score: 0.7462260716970875\n",
      "       d: 16 -------------\n",
      "training accuracy: 0.999585792689241 ,validation accuracy: 0.848\n",
      "f1: 0.5880758807588076 Area under curve score: 0.7370958435526507\n"
     ]
    }
   ],
   "source": [
    "features_upsampled_t, target_upsampled_t = balance_resample(features_train, target_train, 'up', 4)\n",
    "\n",
    "for depth in range(8,17,2):\n",
    "    model = RandomForestClassifier(random_state=12345, max_depth = depth, n_estimators = 1000)\n",
    "    model.fit(features_upsampled_t, target_upsampled_t)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    auc_roc = roc_auc_score(target_valid, model.predict(features_valid))\n",
    "\n",
    "    print('       d:',depth, '-------------')\n",
    "    print('training accuracy:', model.score(features_upsampled_t, target_upsampled_t), \n",
    "          ',validation accuracy:', model.score(features_valid, target_valid))\n",
    "    print('f1:', f1_score(target_valid, predicted_valid), 'Area under curve score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4876\n",
       "0    4781\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_upsampled_t.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it came to upsampling, the classification of 1 observations were multiplied by 4 times. We see that max_depth = 12 and n_estimators = 1000 achieved the highest f1 and auc_roc scores. These scores are better than the imbalanced model and have a better balance of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalance: Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      d: 18 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.851\n",
      "f1: 0.5872576177285319 | Area under curve score: 0.7341202538788368\n",
      "      d: 20 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.8515\n",
      "f1: 0.5846153846153845 | Area under curve score: 0.7315269448228395\n",
      "      d: 22 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.851\n",
      "f1: 0.5872576177285319 | Area under curve score: 0.7341202538788368\n",
      "      d: 24 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.853\n",
      "f1: 0.5916666666666667 | Area under curve score: 0.7363312823170178\n",
      "      d: 26 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.852\n",
      "f1: 0.5877437325905293 | Area under curve score: 0.7337737375599848\n"
     ]
    }
   ],
   "source": [
    "features_downsampled_t, target_downsampled_t = balance_resample(features_train, target_train, 'down', 0.6)\n",
    "\n",
    "for depth in range(18,27,2):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth = depth, n_estimators = 1000)\n",
    "        model.fit(features_downsampled_t, target_downsampled_t)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, model.predict(features_valid))\n",
    "\n",
    "        print('      d:',depth,'---------------')\n",
    "        print('training accuracy:', model.score(features_downsampled_t, target_downsampled_t), \n",
    "              '| validation accuracy:', model.score(features_valid, target_valid))\n",
    "        print('f1:', f1_score(target_valid, predicted_valid), '| Area under curve score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2869\n",
       "1    1219\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled_t.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve an f1 score great than 0.59, we require a 60% cut in customers classified as 0 to create an equal balance between the classes. The hyperparameters required to get this score included max_depth = 24 and n_estimators = 1000. While we did achieve the required score, downsampling seems to be a poor move overall because it is removing rows and also there is still significant class imbalance. Observations of 0's heavily outweight 1's, so I will be running the downsampling process again to achieve closer balance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      d: 18 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.7765\n",
      "f1: 0.558736426456071 | Area under curve score: 0.7565476483781288\n",
      "      d: 20 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.774\n",
      "f1: 0.557729941291585 | Area under curve score: 0.7569299289959451\n",
      "      d: 22 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.773\n",
      "f1: 0.5557729941291585 | Area under curve score: 0.7553404045975404\n",
      "      d: 24 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.772\n",
      "f1: 0.5546875 | Area under curve score: 0.7547189005577641\n",
      "      d: 26 ---------------\n",
      "training accuracy: 1.0 | validation accuracy: 0.7725\n",
      "f1: 0.555229716520039 | Area under curve score: 0.7550296525776523\n"
     ]
    }
   ],
   "source": [
    "features_downsampled_t, target_downsampled_t = balance_resample(features_train, target_train, 'down', 0.27)\n",
    "\n",
    "for depth in range(18,27,2):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth = depth, n_estimators = 1000)\n",
    "        model.fit(features_downsampled_t, target_downsampled_t)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        auc_roc = roc_auc_score(target_valid, model.predict(features_valid))\n",
    "\n",
    "        print('      d:',depth,'---------------')\n",
    "        print('training accuracy:', model.score(features_downsampled_t, target_downsampled_t), \n",
    "              '| validation accuracy:', model.score(features_valid, target_valid))\n",
    "        print('f1:', f1_score(target_valid, predicted_valid), '| Area under curve score:', auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1291\n",
       "1    1219\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled_t.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a greater balance between observations of 0's and 1's, the f1 and Area Under the Curve score have taken a hit. This is most likely due to the cost of deleting data to have a less biased training model to reach a balance between the classes. Overall, both downsampling attempts have proven to be poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalance: Logistic Regression Parameter Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another class balancing approach I wanted to test was in logistic regression model. Below is the before and after the class weight balance seen in the parameter change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before class weight balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.813 ,validation accuracy: 0.8145\n",
      "f1: 0.30131826741996237 Area under curve score: 0.5836566690880421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "auc_roc = roc_auc_score(target_valid, model.predict(features_valid))\n",
    "\n",
    "print('training accuracy:', model.score(features_train, target_train), \n",
    "      ',validation accuracy:', model.score(features_valid, target_valid))\n",
    "print('f1:', f1_score(target_valid, predicted_valid), 'Area under curve score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After class weight balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.7115 ,validation accuracy: 0.705\n",
      "f1: 0.4741532976827095 Area under curve score: 0.6956537634374419\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "auc_roc = roc_auc_score(target_valid, model.predict(features_valid))\n",
    "\n",
    "print('training accuracy:', model.score(features_train, target_train), \n",
    "      ',validation accuracy:', model.score(features_valid, target_valid))\n",
    "print('f1:', f1_score(target_valid, predicted_valid), 'Area under curve score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original logistic regression performed very poorly with an f1 score of 0.3 and auc_roc score of 0.58. \n",
    "\n",
    "With the introduction of class weight balance, we achieve an improved f1 score of 0.47 and auc_roc score of 0.69. Unfortunately, this is still well below the other class balance approaches we have seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all the balance approaches, **upsampling** proved to perform the best with have the highest f1 and area under curve ROC score. The upsampling method with hyperparameters of max_depth = 12 and n_estimators = 1000 will be used with the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      [Test] accuracy of 0.8405\n",
      "f1: 0.6345933562428407 , Area under curve score: 0.7706369636324927\n"
     ]
    }
   ],
   "source": [
    "features_upsampled_t, target_upsampled_t = balance_resample(features_train, target_train, 'up', 4)\n",
    "\n",
    "model = RandomForestClassifier(random_state=12345, max_depth = 12, n_estimators = 1000)\n",
    "model.fit(features_upsampled_t, target_upsampled_t)\n",
    "\n",
    "predicted_test = model.predict(features_test)\n",
    "auc_roc = roc_auc_score(target_test, model.predict(features_test))\n",
    "\n",
    "print('      [Test] accuracy of', model.score(features_test, target_test))\n",
    "print('f1:', f1_score(target_test, predicted_test), ', Area under curve score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters from upsampling, the test model was able to provide an output of f1 = 0.634 and auc_roc = 0.77. This is fairly better than the imbalanced model. The model is now more accurate at testing when a customer will be leaving the bank soon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
